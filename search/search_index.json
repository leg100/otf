{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>OTF is an open-source alternative to Terraform Enterprise, sharing many of its features:</p> <ul> <li>Full Terraform CLI integration</li> <li>Remote execution mode: plans and applies run on servers</li> <li>Agent execution mode: plans and applies run on agents</li> <li>Remote state backend: state stored in PostgreSQL</li> <li>SSO: sign in using an identity provider via OIDC, OAuth, etc.</li> <li>RBAC: control team access to workspaces</li> <li>VCS integration: trigger runs and publish modules from git commits</li> <li>Create and install a Github app to integrate OTF with Github</li> <li>Compatible with much of the Terraform Enterprise/Cloud API</li> <li>Minimal dependencies: requires only PostgreSQL</li> <li>Stateless: horizontally scale servers in pods on Kubernetes, etc</li> <li>Module registry</li> </ul> <p>...and full support for OpenTofu.</p> <p></p> Real-time streaming of a terraform plan <p></p> A status check for a pull request on github.com <p></p> The main page for a workspace <p></p> Setting VCS triggers <p></p> Setting organization-level permissions for a team <p></p> Editing a workspace variable <p></p> Managing workspace access to specific agent pool"},{"location":"caching/","title":"Caching","text":"<p>During the course of a run a number of artifacts may be downloaded from the internet. This can add up to a significant use of your bandwidth, as well as placing a burden on the upstream artifact providers, which may trigger rate limiting. Furthermore, it can slow your runs down while they wait for downloads to complete.</p> <p>OTF by default provides limited caching of artifacts to skip unnecessary downloads. Engine binaries, i.e. the <code>terraform</code> and <code>tofu</code> binaries, are cached to the local filesystem. The <code>--engine-bins-dir</code> flag sets the destination directory.</p> <p>Provider plugins are notoriously tricky to cache. By default they are not cached. Terraform and Tofu allow you to enable a cache by setting the <code>TF_PLUGIN_CACHE_DIR</code> environment variable to a directory. With OTF you can either set this environment variable, or you can set the <code>--plugin-cache</code> and <code>--plugin-cache-dir</code> flags, which take precedence.</p> <p>However, there are caveats with this cache. It is only effective once the lock file contains checksums for the plugin (another reason why you should always check in your lock files to version control).</p> <p>A more problematic caveat is that only Tofu (versions 1.10.0 and higher) supports concurrent use of the cache; Terraform doesn't support concurrent use at all. If you enable the plugin cache in OTF and you have multiple terraform init processes operating concurrently, then you're liable to run into fatal errors.</p> <p>And even then, the concurrency support in Tofu is dependent upon operating system and filesystem support for file locks. On a linux machine or VM this should be fine. If you're using the kubernetes executor and you're using a persistent volume for caching then the volume plugin must support file locks. NFS does provide support, so using something like Filestore for GKE would work. But object storage, such as S3 and GCS, does not.</p>"},{"location":"cli/","title":"CLI","text":"<p><code>otf</code> is the CLI for OTF.</p> <p>Download a release. Ensure you select the client component, <code>otf</code>. The release is a zip file. Extract the <code>otf</code> binary to a directory in your system PATH.</p> <p>Run <code>otf</code> with no arguments to receive usage instructions:</p> <pre><code>Usage:\n  otf [command]\n\nAvailable Commands:\n  agents          Agent management\n  completion      Generate the autocompletion script for the specified shell\n  help            Help about any command\n  organizations   Organization management\n  runs            Runs management\n  state           State version management\n  team-membership Team membership management\n  teams           Team management\n  users           User account management\n  workspaces      Workspace management\n\nFlags:\n  -h, --help           help for otf\n      --token string   API authentication token\n      --url string     URL of OTF server (default \"https://localhost:8080\")\n\nUse \"otf [command] --help\" for more information about a command.\n</code></pre> <p>Credentials are sourced from the same file the terraform CLI uses (<code>~/.terraform.d/credentials.tfrc.json</code>). To populate credentials, run:</p> <pre><code>terraform login &lt;otfd_hostname&gt;\n</code></pre>"},{"location":"dev/","title":"Development","text":"<p>Code contributions are welcome.</p>"},{"location":"dev/#setup-your-machine","title":"Setup your machine","text":"<ul> <li>Clone the repo:</li> </ul> <pre><code>git clone git@github.com:leg100/otf.git\n</code></pre> <ul> <li>Install Go.</li> <li>Install PostgreSQL (optional).</li> </ul>"},{"location":"dev/#documentation","title":"Documentation","text":"<p>The documentation uses Material for MkDocs.</p> <p>The documentation pages are maintained in the <code>./docs</code> directory of the repository. To make small edits it is recommended you click on the <code>Edit this page</code> icon (see top right of this page), which'll take you to Github and prompt you to make a pull request.</p> <p>For larger changes, make the edits locally. Change into the <code>./docs</code> directory in your terminal. First you need to install the python package dependencies:</p> <pre><code>make install\n\n</code></pre> <p>Then serve the docs:</p> <pre><code>make serve\n</code></pre> <p>That builds and runs the documentation site on your workstation at <code>http://localhost:8000</code>. Any changes you make to the documentation are reflected in real-time in the browser.</p> <p>Screenshots in the documentation are largely automated. The browser-based integration tests produce screenshots at various steps. If the environment variable <code>OTF_DOC_SCREENSHOTS=true</code> is present then such a test also writes the screenshot into the documentation directory. Run the following make task from the root of the repo to generate the screenshots:</p> <pre><code>OTF_DOC_SCREENSHOTS=true make test\n</code></pre>"},{"location":"dev/#sql-migrations","title":"SQL migrations","text":"<p>The database schema is migrated using tern. The SQL migration files are kept in the repo in <code>./internal/sql/migrations</code>. Upon startup <code>otfd</code> automatically migrates the DB to the latest version.</p>"},{"location":"dev/#html-path-helpers","title":"HTML path helpers","text":"<p>Rails-style path helpers are generated using <code>go generate</code>. The path specifications are maintained in <code>./ui/paths/paths.yaml</code>. After making changes to the specs run the following make task to generate the helpers:</p> <ul> <li><code>make paths</code></li> </ul>"},{"location":"dev/#web-development","title":"Web development","text":"<p>If you're making changes to web templates then you may want to enable developer mode: set the environment variable <code>DEV_MODE=1</code>. Once enabled you will be able to see changes without restarting <code>otfd</code>.</p> <p>OTF uses Tailwind CSS to generate CSS classes. Run the following make task to generate the CSS:</p> <ul> <li><code>make live/tailwind</code></li> </ul> <p>Note</p> <p>To install tailwind first ensure you've installed <code>npm</code> and then run <code>npm install -D tailwindcss</code></p> <p>For templates, OTF uses Templ, an alternative to go's built in templates that generates go code from a proprietary syntax. Templ provides a handy command to watch for changes and generate go code before reloading your browser to show changes in real-time. A make task is provided to run this command:</p> <ul> <li><code>make live/templ</code></li> </ul> <p>The two commands above are combined into the following make task, to watch for all changes to templates, tailwind CSS classes and static assets such as images:</p> <ul> <li><code>make live</code></li> </ul>"},{"location":"dev/#helm-charts","title":"Helm charts","text":"<p>The helm charts are maintained in the <code>./charts</code> directory of the repo. </p>"},{"location":"dev/#bumping-the-chart-version","title":"Bumping the chart version","text":"<p>If you make any changes to a chart you need to bump its chart version. You can either do that by hand in <code>Chart.yaml</code>, or using <code>make</code>:</p> <pre><code># requires `yq`\n#\n# To update the otfd chart version\nCHART=otfd make bump-chart-version\n#\n# To update the otf-agent chart version\nCHART=otf-agent make bump-chart-version\n</code></pre>"},{"location":"dev/#generating-readmemds","title":"Generating README.md's","text":"<p>Each chart's <code>README.md</code> is generated from a template, <code>README.md.gotmpl</code> in the same directory, using helm-docs. Therefore any changes must be made to <code>README.md.gotmpl</code> and not <code>README.md</code>. To update all templated README.md's, run the following from the root of the repo:</p> <pre><code>make helm-docs\n</code></pre> <p>Any changes to the version or to the <code>values.yaml</code> file are automatically reflected in the generated <code>README.md</code>. </p>"},{"location":"dev/#linting","title":"Linting","text":"<p>To lint the charts to check for any errors run <code>helm lint</code>:</p> <pre><code># lint the otfd chart\nhelm lint ./charts/otfd\n# lint the otf-agent chart\nhelm lint ./charts/otf-agent\n</code></pre>"},{"location":"dev/#deploy-and-test-otfd-chart","title":"Deploy and test otfd chart","text":"<p>To deploy the <code>./charts/otfd</code> chart to a cluster to the namespace <code>otfd-test</code> with pre-configured defaults along with PostgreSQL:</p> <pre><code>make deploy-otfd\n</code></pre> <p>To test the chart (assumes release is named <code>otfd</code>):</p> <pre><code>make test-otfd\n</code></pre>"},{"location":"dynamic_credentials/","title":"Dynamic Provider Credentials","text":"<p>OTF supports dynamic provider credentials, avoiding the need for static credentials. Furthermore they let you use your cloud provider's auth tools to scope permissions based on the properties of your run, including the organization, workspace and run phase.</p>"},{"location":"dynamic_credentials/#how-they-work","title":"How they work","text":"<p>Essentially they rely on first establishing a trust relationship between OTF and your cloud provider. You can define IAM policies to specify organizations or workspaces that are allowed to access specific cloud resources.</p> <p>Once that initial setup is complete, for each plan or apply the following steps are carried out:</p> <ol> <li>OTF generates a token and configures your cloud provider to send that token when it authenticates.</li> <li>The cloud provider receives the token and sends a request to OTF to retrieve the public key to verify the token.</li> <li>The cloud provider upon success sends temporary credentials to OTF.</li> <li>Those credentials are then used as the plan or apply proceeds and makes API calls to your cloud provider.</li> <li>The credentials are discarded upon completion.</li> </ol>"},{"location":"dynamic_credentials/#setup","title":"Setup","text":"<p>The setup steps are not simple and differ according to cloud provider. OTF implements Terraform Cloud's dynamic provider credentials implementation, using the exact same environment variables, allowing for configuration of multiple provider blocks. You can therefore rely entirely on its documentation and follow its instructions to setup dynamic provider credentials for your cloud provider.</p> <p>Thus far the following cloud providers are supported in OTF:</p> <ul> <li>GCP</li> <li>AWS</li> <li>Azure</li> </ul> <p>Warning</p> <p>Only GCP support has been fully tested by the developers. Please report success or bugs with the AWS and Azure providers on Github Issues / Slack.</p> <p>There are a few pre-requisites specific to OTF you need to first carry out:</p> <ol> <li> <p>Generate a public key pair:</p> <p><code>openssl genrsa -out key.pem 4096 openssl rsa -in key.pem -pubout -out public.pem</code></p> </li> <li> <p>Configure <code>otfd</code> with public key pair:</p> <p><code>otfd --public-key-path public.pem --private-key-path key.pem</code></p> </li> <li> <p>Ensure external access to metadata endpoints:</p> <p>In order to verify signed JWTs, cloud platforms must have network access to the following static OIDC metadata endpoints within OTF:</p> <ul> <li><code>/.well-known/openid-configuration</code> - standard OIDC metadata.</li> <li><code>/.well-known/jwks</code> - OTF`s public key(s) that cloud platforms use to verify the authenticity of tokens that claim to come from OTF.</li> </ul> <p>Note</p> <p>Not all cloud providers have this requirement. For example, GCP permits uploading the key. If you want to do this, the key can be retrieved from the <code>./.well-known/jwks</code> path above, e.g.:</p> <pre><code>curl https://localhost:8080/.well-known/jwks -o key-to-upload.json\n</code></pre> <p>The benefit of this approach is that you don't need to expose the endpoints above publicly.</p> </li> <li> <p>When following the provider specific documentation, you'll be prompted to enter an issuer, which is the URL of your OTF installation. The URL's hostname must match the value of the <code>--hostname</code> flag.</p> </li> </ol>"},{"location":"dynamic_credentials/#differences","title":"Differences","text":"<p>There are some minor differences where OTF diverges from the Terraform Cloud documentation, mainly around Terraform Cloud projects, which OTF does not support:</p> <ul> <li>The token's subject in TFC has the format: <code>organization:&lt;org&gt;:project:&lt;project&gt;:workspace:&lt;workspace&gt;:run-phase:&lt;phase&gt;</code> Whereas OTF does not have support for projects. Therefore the subject format is <code>organization:&lt;org&gt;:workspace:&lt;workspace&gt;:run-phase:&lt;phase&gt;</code>.</li> <li>Their example terraform configurations reference projects, but OTF does not support projects. Therefore you'll need to amend the terraform configurations accordingly if you decide to use them.</li> </ul>"},{"location":"engines/","title":"Engines","text":"<p>An engine is the program responsible for executing run commands like <code>plan</code> and <code>apply</code>. OTF provides support for two engines:</p> <ul> <li><code>terraform</code></li> <li><code>tofu</code></li> </ul> <p>The default engine is <code>terraform</code>. This can be overridden with the <code>otfd</code> flag <code>--default-engine</code>.</p> <p>Warning</p> <p>If you're running more than one instance of <code>otfd</code>, take care to set this flag to the same value on each instance. Doing otherwise will lead to unpredictable results.</p> <p>When you create a workspace, it'll use the default engine. You can override the engine for a workspace in its settings.</p> <p>When you create a run OTF will download the workspace's engine if it hasn't already been downloaded. The engine binaries are downloaded to the directory specified by the flag <code>--engine-bins-dir</code>.</p>"},{"location":"executors/","title":"Executors","text":"<p>An executor is responsible for executing jobs, i.e. plans and applies. There are two types of executor:</p> <ul> <li><code>fork</code></li> <li><code>kubernetes</code></li> </ul> <p>The executor is set with the <code>--executor</code> flag. The flag is applicable to both <code>otfd</code> and <code>otf-agent</code>, which determines how jobs scheduled to that process are executed. For example, you could set <code>otfd</code> to use <code>fork</code> but if a job is scheduled to run on an <code>otf-agent</code> then the job will use whatever executor it has set.</p>"},{"location":"executors/#fork","title":"Fork","text":"<p>Fork is the default executor. It forks terraform (or tofu) processes as children of the <code>otfd</code> or <code>otf-agent</code> process.</p> <p>The maximum number of forked processes is set with the --concurrency flag.</p> <p>Note</p> <p>If you want to scale processes beyond a single host with the <code>fork</code> executor then you can either run <code>otfd</code> on other hosts to form an OTF cluster, or run <code>otf-agent</code> on other hosts. See runners for more details on agents.</p>"},{"location":"executors/#kubernetes","title":"Kubernetes","text":"<p>The kubernetes executor executes jobs on kubernetes. Each job is run as a kubernetes job.</p> <p>This executor is only functional when <code>otfd</code> or <code>otf-agent</code> is deployed via the helm charts to a kubernetes cluster.</p> <p>There are a number of flags that customise the jobs:</p> <ul> <li><code>--kubernetes-request-cpu</code></li> <li><code>--kubernetes-request-memory</code></li> <li><code>--kubernetes-ttl-after-finish</code></li> </ul> <p>It's advisable to provide a persistent volume for the cache. Otherwise the terraform or tofu binary is downloaded at the beginning of every job. See the helm chart settings to enable the persistent volume claim. You will need to make available a persistent volume that supports the ReadWriteMany access mode.</p>"},{"location":"github_app/","title":"Github app","text":"<p>OTF provides the ability to create a Github app. The app can then be used as an alternative to a personal access token for a VCS provider, offering the following advantages:</p> <ul> <li>Unlike a personal token, an app is not necessarily tied to an individual's personal Github account. Instead it can be owned and installed into a Github organization. If an individual leaves an organization then the app continues to function.</li> <li>The app can be installed into more than Github account. For instance, if you install the app into Github organizations <code>dev</code> and <code>prod</code> you can then create VCS providers for those installations respectively, restricting their access to the repositories belonging to each organization.</li> <li>An app comes with its own webhook. Therefore, unlike with personal tokens, OTF does not need to create webhooks on Github repositories. This can be advantage if you want to overcome the maximum 20 webhook per-repo limit (OTF creates a separate webhook on a repo for each VCS provider if using a personal token).</li> <li>An app has a higher maximum possible rate-limit.</li> <li>The github app creation process automatically persists the app credentials to the database. There is no copying-and-pasting of credentials involved.</li> </ul> <p>Note</p> <p>Github apps also have access to a richer API for status checks. A future version of OTF will take advantage of this.</p>"},{"location":"github_app/#create-the-app","title":"Create the app","text":"<p>Select site in the top right corner menu to take you to the site settings page:</p> <p></p> <p>Select GitHub app. You are then prompted to create an app:</p> <p></p> <p>Select the link to create a new app. You are presented with a form to create the app:</p> <p></p> <p>An app has an owner. By default your github personal account is the owner. If you would prefer a Github organization to own the application then enter the name of the organization.</p> <p>An app is private by default. That means the app can only be installed into the Github account that owns the app, and only repositories in that account will be accessible to OTF. If you want to install the app into more than one Github account then you need to select the Public checkbox. (This can be changed once the app has been created, via the app settings page on Github).</p> <p>Click Create and you are redirected to Github. You are given the opportunity to set a name (it must be globally unique and cannot match the name of a Github account):</p> <p></p> <p>Click the Create GitHub App for ... button.</p> <p>You're then redirected back to OTF, where details of the app are now visible:</p> <p></p>"},{"location":"github_app/#install-the-app","title":"Install the app","text":"<p>Once you've created the app you need to install it.</p> <p>On the Github app page, click the Install button:</p> <p></p> <p>You are re-directed to Github, where you can select the repositories that are to be made accessible to OTF:</p> <p></p> <p>Note</p> <p>If you created a public app earlier you will first be presented with a choice of accounts to install the app into.</p> <p>Click the Install button and you'll be re-directed back to OTF. The installation should now be listed:</p> <p></p> <p>You can create a VCS provider from the installation.</p>"},{"location":"install/","title":"Installation","text":""},{"location":"install/#requirements","title":"Requirements","text":"<ul> <li>Linux - the server and agent components are tested on Linux only; the client CLI should work on all platforms.</li> <li>PostgreSQL - at least version 12.</li> <li>Terraform &gt;= 1.2.0</li> <li>An SSL certificate.</li> </ul>"},{"location":"install/#download","title":"Download","text":"<p>There are three components that can be downloaded:</p> <ul> <li><code>otfd</code> - the server daemon</li> <li><code>otf</code> - the client CLI</li> <li><code>otf-agent</code> - the agent daemon</li> </ul> <p>Download them from Github releases.</p> <p>The server and agent components are also available as docker images:</p> <ul> <li><code>leg100/otfd</code></li> <li><code>leg100/otf-agent</code></li> </ul>"},{"location":"install/#install-using-docker-compose","title":"Install using docker compose","text":"<p>You can install and run OTF and postgres in a container using docker compose.</p> <p>First clone the repo:</p> <pre><code>git clone https://github.com/leg100/otf\ncd otf\n</code></pre> <p>Populate an <code>.env</code> file with a secret and site token:</p> <pre><code>cat &gt; .env &lt;&lt;EOF\nOTF_SECRET=6b07b57377755b07cf61709780ee7484\nOTF_SITE_TOKEN=my-site-token\nEOF\n</code></pre> <p>Note</p> <p>The secret must be a hex-encoded 16-byte array. Generate using <code>openssl rand -hex 16</code>.</p> <p>Then create and start the containers:</p> <pre><code>docker compose up\n</code></pre> <p>Login to the web app at <code>http://localhost:8080</code> and use the site token configured above to login.</p> <p>Warning</p> <p>Use at your own risk. This exposes port 8080 on all interfaces, using plaintext HTTP. It also hardcodes the postgres account credentials.</p>"},{"location":"install/#install-helm-chart","title":"Install helm chart","text":"<p>You can install OTF onto Kubernetes using helm charts.</p> <p>Add the helm repository:</p> <pre><code>helm repo add otf https://leg100.github.io/otf-charts\n</code></pre> <p>Then follow instructions for installing the relevant chart:</p> <ul> <li>otfd</li> <li>otf-agent</li> </ul>"},{"location":"install/#install-using-go","title":"Install using <code>go</code>","text":"<p>You'll need Go. Run:</p> <pre><code>go install github.com/leg100/otf/cmd/otfd@latest\n</code></pre> <p>That'll install the latest <code>otfd</code> binary into your go bin directory (defaults to <code>$HOME/go/bin</code>).</p> <p>See the quickstart for configuring and running <code>otfd</code> locally.</p>"},{"location":"notifications/","title":"Notifications","text":"<p>OTF can send notifications for run state transitions. OTF implements the TFC notifications API, which means you can use the same documented API endpoints to configure notifications. Alternatively you can use the <code>tfe</code> terraform provider.</p> <p>Note</p> <p>Currently you cannot configure notifications via the UI.</p> <p>Support exists for the following destination types:</p> <ul> <li><code>generic</code>: Generic HTTP POST notifications</li> <li><code>slack</code>: Slack messages</li> <li><code>gcppubsub</code>: GCP Pub/Sub topic messages (*OTF specific)</li> </ul> <p>Note</p> <p>Currently there is no support for the <code>email</code> or <code>microsoft-teams</code> destination types (which TFC does support).</p>"},{"location":"notifications/#gcp-pub-sub","title":"GCP Pub Sub","text":"<p>OTF can send notifications to a GCP Pub/Sub topic. To configure these notifications see the TFC notifications API documentation, in particular the endpoint for creating a notification configuration.</p> <p>For the <code>destination-type</code> field, use <code>gcppubsub</code>.</p> <p>For the <code>url</code> field, enter <code>gcppubsub://&lt;project-id&gt;/&lt;topic&gt;</code>, where <code>&lt;project_id&gt;</code> is the GCP project ID and <code>&lt;topic&gt;</code> is the Pub/Sub topic ID.</p> <p>Ensure <code>otfd</code> has access to default credentials for a service account which has necessary permissions to publish messages to the configured topic.</p> <p>The payload of the messages is the same as that documented for the <code>generic</code> destination type (using the JSON format).</p> <p>Additionally, attributes are added to each message:</p> key value <code>otf.ninja/v1/workspace.name</code> <code>&lt;workspace_name&gt;</code> <code>otf.ninja/v1/workspace.id</code> <code>&lt;workspace_id&gt;</code> <code>otf.ninja/v1/tags/&lt;tag_name&gt;</code> <code>true</code> <p>Attributes permit you to filter messages from a subscription in GCP.</p>"},{"location":"quickstart/","title":"Quickstart","text":"<p>These steps will get you started with running <code>otfd</code> on your local system.</p> <p>Download a release of the server component, <code>otfd</code>. The release is a zip file. Extract the <code>otfd</code> binary to your current directory.</p> <p>Ensure you have access to a postgres server. <code>otfd</code> by default assumes postgres is running locally, accessible via a domain socket in <code>/var/run/postgresql</code>, and defaults to using a database named <code>otf</code>. You need to create the database first:</p> <pre><code>createdb otf\n</code></pre> <p>At a minimum, <code>otfd</code> requires a secret and a means of authentication. For the purposes of this quickstart we'll use a site token:</p> <pre><code>&gt; ./otfd --secret=6b07b57377755b07cf61709780ee7484 --site-token=my-token\n2022-10-30T20:06:10Z INF started cache max_size=0 ttl=10m0s\n2022-10-30T20:06:10Z INF successfully connected component=database path=postgres:///otf?host=/var/run/postgresql\n2022-10-30T20:06:10Z INF goose: no migrations to run. current version: 20221017170815 compone\nnt=database\n2022-10-30T20:06:10Z INF started server address=[::]:8080 ssl=false\n</code></pre> <p>Note</p> <p>The secret must be a hex-encoded 16-byte array. Generate using <code>openssl rand -hex 16</code>.</p> <p>You have now successfully installed <code>otfd</code> and confirmed you can start <code>otfd</code> with minimal configuration. Proceed to create your first organization.</p>"},{"location":"quickstart/#create-organization","title":"Create organization","text":"<p>Navigate to the web app in your browser, http://localhost:8080:</p> <p></p> <p>Note it announces you have <code>no authenticators configured</code>. The normal method of login is to use SSO signin, via Github etc, but in this quickstart we're using the site admin account. Click on <code>site admin</code> in the bottom right, and use your token to login.</p> <p></p> <p></p> <p>Go to organizations &gt; New Organization. Give the organization a name and create.</p> <p> </p>"},{"location":"quickstart/#run-terraform","title":"Run Terraform","text":"<p>Note</p> <p>The terraform CLI will be connecting to the server and it expects to make a verified SSL connection. Therefore we need to configure SSL first.</p> <p>Generate a self-signed SSL certificate and key:</p> <pre><code>openssl req -x509 -newkey rsa:4096 -sha256 -keyout key.pem -out cert.crt -days 365 -nodes -subj '/CN=localhost' -addext 'subjectAltName=DNS:localhost'\n</code></pre> <p>Ensure your system trusts the generated cert. For example, on Ubuntu based systems:</p> <pre><code>sudo cp cert.crt /usr/local/share/ca-certificates\nsudo update-ca-certificates\n</code></pre> <p>Now return to the terminal in which <code>otfd</code> is running. You'll need to kill it and start it again, this time with SSL enabled:</p> <pre><code>&gt; ./otfd --secret=6b07b57377755b07cf61709780ee7484 --site-token=my-token --ssl --cert-file=cert.crt --key-file=key.pem\n</code></pre> <p>Terraform needs to use your token to authenticate with <code>otfd</code>:</p> <pre><code>terraform login localhost:8080\n</code></pre> <p>Enter <code>yes</code> to proceed. A browser window is opened where you give consent to <code>terraform</code> to access your OTF account:</p> <p></p> <p>Once you give your consent you should be notified you can close the browser and return to the terminal:</p> <p></p> <p>In the terminal you should see the confirmation of success:</p> <pre><code>Success! Terraform has obtained and saved an API token.\n</code></pre> <p>Now we'll write some terraform configuration. Configure the terraform backend and define a resource:</p> <pre><code>cat &gt; main.tf &lt;&lt;EOF\nterraform {\n  cloud {\n    hostname = \"localhost:8080\"\n    organization = \"default\"\n\n    workspaces {\n      name = \"dev\"\n    }\n  }\n}\n\nresource \"null_resource\" \"quickstart\" {}\nEOF\n</code></pre> <p>Initialize terraform:</p> <pre><code>terraform init\n</code></pre> <p>Run a plan:</p> <pre><code>terraform plan\n</code></pre> <p>That starts a run on the server. You can click on the link to the run to view status and logs.</p> <p>And apply:</p> <pre><code>terraform apply\n</code></pre> <p>This starts another run on the server. Again you can click on the link to see logs.</p> <p>You have reached the end of this quickstart guide. Have a look at the remainder of the documentation to further complete the installation of OTF, to setup SSO, run agents, etc.</p>"},{"location":"rbac/","title":"RBAC","text":"<p>The authorization model largely follows that of Terraform Cloud/Enterprise. An organization comprises a number of teams. A user is a member of one or more teams. Teams are assigned permissions permitting access to various functionality. Team permissions can be assigned at two levels: on organizations and on individual workspaces.</p>"},{"location":"rbac/#users","title":"Users","text":"<p>A user is created via one of several methods:</p> <ul> <li>A user successfully logs into the site for the first time via an identity provider.</li> <li>A site admin creates a user via the CLI/API.</li> <li>If a user is added to a team and no user with the specified username exists.</li> </ul> <p>A user without team membership has no permissions other than the ability to create organizations (which can be disabled).</p>"},{"location":"rbac/#teams","title":"Teams","text":"<p>Only owners can create teams and manage team membership. To add a user to a team, a username is specified. If no user exists with that username then the user is automatically created.</p> <p>A new team possesses no permissions until they are assigned.</p>"},{"location":"rbac/#owners","title":"Owners","text":"<p>Every organization has an <code>owners</code> team. The user that creates an organization becomes its owner. The owners team must have at least one member and it cannot be deleted.</p> <p>Members of the owners team possess broad privileges across an organization. Owners are the only users permitted to alter organization-level permissions. They are also automatically assigned all the organization-level permissions; these permissions cannot be unassigned.</p>"},{"location":"rbac/#permissions","title":"Permissions","text":"<p>Permissions are assigned to teams on two levels: organizations and workspaces. Organization permissions confer privileges across the organization:</p> <ul> <li>Manage Workspaces: Allows members to create and administrate all workspaces within the organization.</li> <li>Manage VCS Settings: Allows members to manage the set of VCS providers available within the organization.</li> <li>Manage Registry: Allows members to publish and delete modules within the organization.</li> </ul> <p></p> <p>Workspace permissions confer privileges on the workspace alone, and are based on the fixed permission sets of TFC/TFE:</p> <ul> <li>Read</li> <li>Plan</li> <li>Write</li> <li>Admin</li> </ul> <p></p> Workspace permissions on workspace settings page <p>See the TFC/TFE documentation for more information on the privileges each permission set confers.</p>"},{"location":"rbac/#site-admins","title":"Site Admins","text":"<p>Site admins possesses supreme privileges across an OTF cluster. There are two ways to assume the role:</p> <ul> <li>Use a site token to login as the <code>site-admin</code> user</li> <li>Promote users to the role using the <code>--site-admins</code> flag</li> </ul>"},{"location":"registry/","title":"Module Registry","text":"<p>OTF includes a registry of terraform modules. You can publish modules to the registry from a git repository and source the modules in your terraform configuration.</p>"},{"location":"registry/#publish-module","title":"Publish module","text":"<p>To publish a module, go to the organization main menu, select modules and click publish</p> <p></p> <p>You then need to select a VCS provider. If none are visible you need to first create a provider.</p> <p></p> <p>Connect to the provider and you are presented with a list of git repositories. Select the repository that contains the module you want to publish. If the repository is not visible you can enter its path instead.</p> <p></p> <p>Note</p> <p>Only the first 100 repositories found on your provider are shown.</p> <p>Select a repository. OTF then publishes the module.</p> <p></p> <p>Note</p> <p>Ensure your repository has at least one tag that looks like a semantic version. Otherwise OTF will fail to publish the module.</p> <p>OTF retrieves the repository's git tags. For each tag that looks like a semantic version, e.g. <code>v1.0.0</code> or <code>0.10.3</code>, it'll download the contents of the repository for each tag and publish a module with that version. You should then be redirected to the module's page, containing information regarding its resources, inputs and outputs, along with usage instructions.</p> <p>A webhook is also added to the repository. Any tags pushed to the repository will trigger the webhook and new module versions will be published.</p>"},{"location":"runners/","title":"Runners","text":"<p>A runner handles the execution of runs. There are two types of runners:</p> <ul> <li>The runner built into <code>otfd</code>, referred to as a server runner.</li> <li>A separate process, <code>otf-agent</code>, referred to as an agent runner or just an agent.</li> </ul>"},{"location":"runners/#server-runners","title":"Server runners","text":"<p>A server runner handles runs for workspaces that are configured with the remote execution mode. It's built into the <code>otfd</code> process, so whenever you run <code>otfd</code> you are automatically running a server runner.</p>"},{"location":"runners/#agent-runners","title":"Agent runners","text":"<p>An agent handles runs for workspaces that are configured with the agent execution mode. It's invoked as a dedicated process, <code>otf-agent</code>.</p> <p>An agent belongs to an agent pool. An agent pool is a group of <code>otf-agent</code> processes that can be used to communicate with isolated, private, or on-premises infrastructure. Each agent pool has its own set of tokens which are not shared across pools. When a workspace is configured to execute runs using the agent execution mode, any available agent in that workspace's assigned agent pool is eligible to execute the run.</p> <p>Note</p> <p>Agents are functionally equivalent to Terraform Cloud Agents.</p>"},{"location":"runners/#walkthrough-pool-agents","title":"Walkthrough: pool agents","text":"<p>First, create an agent pool in your organization. Go to the organization main menu and select Agent Pools.</p> <p></p> <p>Select New agent pool to reveal the form.</p> <p></p> <p>Give the pool a name and click Create agent pool.</p> <p></p> <p>By default you can assign any workspace to the agent pool. To grant access only to specific workspaces, select Grant access to specific workspaces.</p> <p></p> <p>Select a workspace from the dropdown menu and it should be added to the list of granted workspaces.</p> <p></p> <p>Click Save changes to persist the change.</p> <p>You then need to assign a workspace to the pool. Go to the settings of a workspace and change the execution mode to agent:</p> <p></p> <p>Click Save changes and return to the agent pool. You should see that the workspace is both granted and assigned.</p> <p></p> <p>Now create an agent token. A pool agent needs to authenticate with a token in order to join a pool. Click New token to reveal the form.</p> <p></p> <p>Give the token a description and click Create token.</p> <p></p> <p>Copy the token to your system clipboard. Now you can run the agent:</p> <pre><code>otf-agent --token &lt;token&gt; --url https://&lt;otfd-hostname&gt;\n</code></pre> <p>The agent should confirm it has registered successfully:</p> <pre><code>2023/12/04 21:52:06 INFO starting agent version=unknown\n2023/12/04 21:52:06 INFO registered successfully agent.id=agent-NGB0H1QskahiN9xR agent\n.server=false agent.status=idle agent.ip_address=192.168.1.155 agent.pool_id=apool-d68\nab60a67ccf4fc\n2023/12/04 21:52:06 INFO waiting for next job\n</code></pre> <p>Go to the agent pool and you should see the agent listed:</p> <p></p> <p>You've successfully reached the end of this walkthrough. Any runs triggered on the workspace above will now be executed on the agent. You can create more agent pools and agents and assign workspaces to specific pools, giving you control over where runs are executed.</p>"},{"location":"testing/","title":"Tests","text":""},{"location":"testing/#unit-tests","title":"Unit tests","text":"<p>Change into the repo directory and run unit tests:</p> <pre><code>go test -short ./...\n</code></pre>"},{"location":"testing/#integration-tests","title":"Integration tests","text":"<p>Integration tests require:</p> <ul> <li>docker compose</li> <li>terraform &gt;= 1.2.0</li> <li>Chrome</li> </ul> <p>The following runs integration tests:</p> <pre><code>go test ./internal/integration...\n</code></pre> <p>The tests first stands up external services using docker compose:</p> <ul> <li>postgres (integration tests require a real database)</li> <li>squid cache (speeds up tests by caching terraform providers)</li> <li>GCP pub/sub emulator (necessary for the GCP pub/sub integration test)</li> </ul>"},{"location":"testing/#disable-headless-mode","title":"Disable headless mode","text":"<p>Browser-based tests spawn a headless Chrome process. In certain situations it can be useful to disable headless mode, e.g. if a test is stuck on a certain page and you want to know which page. To disable headless mode:</p> <pre><code>export OTF_E2E_HEADLESS=false\n</code></pre> <p></p> Integration tests with headless mode disabled"},{"location":"testing/#more-verbose-logging","title":"More verbose logging","text":"<p>By default, the integration tests don't print the logs from the OTF daemons they spawn. To enable logging with a verbosity of 1, set the following environment variable:</p> <pre><code>export OTF_INTEGRATION_TEST_ENABLE_LOGGER=yes go test -v ./internal/integration\n</code></pre> <p>Because the tests run in parallel and each test runs its own daemon, you'll see the logs from multiple daemons intermingled. You'll instead probably want to run one test at a time, and to stop at the first failing test:</p> <pre><code>export OTF_INTEGRATION_TEST_ENABLE_LOGGER=yes go test -v ./internal/integration -parallel 1 -failfast\n</code></pre> <p>This can be helpful for diagnosing the cause of a failing test.</p>"},{"location":"testing/#api-tests","title":"API tests","text":"<p>Tests from the go-tfe project are routinely run to ensure OTF correctly implements the documented Terraform Cloud API.</p> <p>The make task:</p> <pre><code>make go-tfe-tests\n</code></pre> <p>performs the following steps:</p> <ul> <li>Starts a docker compose stack of <code>otfd</code>, postgres, and squid</li> <li>Runs a subset of <code>go-tfe</code> tests against that stack</li> </ul> <p>The tests require the following environment variables:</p> <ul> <li><code>GITHUB_POLICY_SET_IDENTIFIER</code>: set to a github repo on which the tests can create webhooks.</li> <li><code>OAUTH_CLIENT_GITHUB_TOKEN</code>: a personal access token with permissions to create webhooks on the above repo.</li> </ul> <p>Note</p> <p>You can instead manually invoke API tests using the scripts in <code>./hack</code>. The tests first require <code>otfd</code> to be running at <code>https://localhost:8080</code>, with a site token set to <code>site-token</code>. These settings can be overridden with the environment variables <code>TFE_ADDRESS</code> and <code>TFE_TOKEN</code>.</p> <p>Note</p> <p>The tests create webhooks on the github repository specified in <code>GITHUB_POLICY_SET_IDENTIFIER</code>. The tests should delete the webhooks once they're finished. However, should the tests fail and/or panic, then the webhooks won't be deleted and you'll quickly run into the maximum limit of 20 webhooks Github imposes and you'll need to delete them manually.</p>"},{"location":"tfc_migration/","title":"State Migration","text":"<p>This is a guide for migrating your existing terraform state into OTF.</p>"},{"location":"tfc_migration/#migrating-from-terraform-cloud-enterprise","title":"Migrating from Terraform Cloud / Enterprise","text":"<p>If you're currently using Terraform Cloud or Terraform Enterprise, you are either using the <code>remote</code> backend or the newer <code>cloud</code> block. See the relevant instructions below.</p>"},{"location":"tfc_migration/#cloud-block-migration","title":"Cloud block migration","text":"<ol> <li> <p>If you're using the the newer <code>cloud</code> block, your existing configuration will look something like this:</p> <pre><code>terraform {\n  cloud {\n    hostname = \"app.terraform.io\"\n    organization = \"automatize\"\n\n    workspaces {\n      name = \"my-workspace\"\n    }\n  }\n}\n</code></pre> </li> <li> <p>Temporarily update the configuration to use <code>remote</code> instead:</p> <pre><code>terraform {\n  backend \"remote\" {\n    hostname = \"app.terraform.io\"\n    organization = \"automatize\"\n\n    workspaces {\n      name = \"my-workspace\"\n    }\n  }\n}\n</code></pre> <p>Note</p> <p>This step is necessary because <code>terraform</code> does not allow state to be migrated when using the cloud block configuration. Once you've migrated the state you can re-introduce the cloud block (see below).</p> </li> <li> <p>Remove the <code>.terraform</code> directory:</p> <pre><code>rm -r .terraform\n</code></pre> </li> <li> <p>Then follow the Remote backend migration instructions below.</p> </li> </ol>"},{"location":"tfc_migration/#remote-backend-migration","title":"Remote backend migration","text":"<ol> <li> <p>If you're using the <code>remote</code> backend, your existing configuration will look something like this:</p> <pre><code>terraform {\n  backend \"remote\" {\n    hostname = \"app.terraform.io\"\n    organization = \"automatize\"\n\n    workspaces {\n      name = \"my-workspace\"\n    }\n  }\n}\n</code></pre> </li> <li> <p>To migrate to OTF you only need to update the hostname:</p> <pre><code>terraform {\n  backend \"remote\" {\n    hostname = \"otf.example.com\"\n    organization = \"automatize\"\n\n    workspaces {\n      name = \"my-workspace\"\n    }\n  }\n}\n</code></pre> </li> <li> <p>Ensure you have credentials for your hostname:</p> <pre><code>terraform login otf.example.com\n</code></pre> </li> <li> <p>And then migrate the state:</p> <pre><code>terraform init -migrate-state\n</code></pre> <p>You should see output similar to the following:</p> <pre><code>Initializing the backend...\nBackend configuration changed!\n\nTerraform has detected that the configuration specified for the backend\nhas changed. Terraform will now check for existing state in the backends.\n\nDo you want to copy existing state to the new backend?\n  Pre-existing state was found while migrating the previous \"remote\" backend to the\n  newly configured \"remote\" backend. No existing state was found in the newly\n  configured \"remote\" backend. Do you want to copy this state to the new \"remote\"\n  backend? Enter \"yes\" to copy and \"no\" to start with an empty state.\n\n  Enter a value: yes\n\nSuccessfully configured the backend \"remote\"! Terraform will automatically\nuse this backend unless the backend configuration changes.\n</code></pre> </li> <li> <p>Optional: you can update the configuration to use the <code>cloud</code> block. Doing so allows you to use newer features such as workspace tags:</p> <pre><code>terraform {\n  cloud {\n    hostname = \"otf.example.com\"\n    organization = \"automatize\"\n\n    workspaces {\n      name = \"my-workspace\"\n    }\n  }\n}\n</code></pre> </li> <li> <p>You'll then need to reinitialize:</p> <pre><code>terraform init\n</code></pre> </li> <li> <p>You'll be prompted to enter <code>yes</code> or <code>no</code>. Enter <code>yes</code> to complete the switch to using the <code>cloud</code> block:</p> <pre><code>Initializing Terraform Cloud...\nMigrating from backend \"remote\" to Terraform Cloud.\nDo you wish to proceed?\n  As part of migrating to Terraform Cloud, Terraform can optionally copy your\n  current workspace state to the configured Terraform Cloud workspace.\n\n  Answer \"yes\" to copy the latest state snapshot to the configured\n  Terraform Cloud workspace.\n\n  Answer \"no\" to ignore the existing state and just activate the configured\n  Terraform Cloud workspace with its existing state, if any.\n\n  Should Terraform migrate your existing state?\n\n  Enter a value: yes\n</code></pre> <p>You should then be informed the migration was successful:</p> <pre><code>Initializing provider plugins...\n- Reusing previous version of hashicorp/null from the dependency lock file\n- Using previously-installed hashicorp/null v3.2.1\n\nTerraform Cloud has been successfully initialized!\n</code></pre> <p>Note</p> <p>Despite what the output says, <code>terraform</code> does not actually copy any state across; your state has already been uploaded to the relevant OTF workspace in a previous step.</p> </li> </ol>"},{"location":"tfc_migration/#migrating-from-other-state-backends","title":"Migrating from other state backends","text":"<p>If you're currently using a configuration other the <code>remote</code> backend or the <code>cloud</code> block, e.g. s3 or local, etc., then follow these steps:</p> <ol> <li> <p>Replace your existing backend configuration, e.g. <code>s3</code>:</p> <pre><code>terraform {\n  backend \"s3\" {\n    bucket = \"mybucket\"\n    key    = \"path/to/my/key\"\n    region = \"us-east-1\"\n  }\n}\n</code></pre> <p>with a <code>cloud</code> block for OTF:</p> <pre><code>terraform {\n  cloud {\n    hostname = \"otf.example.com\"\n    organization = \"automatize\"\n\n    workspaces {\n      name = \"my-workspace\"\n    }\n  }\n}\n</code></pre> <p>See the cloud settings documentation for help with configuration of the <code>cloud</code> block.</p> </li> <li> <p>And then reinitialize:</p> <pre><code>terraform init\n</code></pre> </li> <li> <p>You'll be prompted to enter <code>yes</code> or <code>no</code>. Enter <code>yes</code> to complete the migration:</p> <pre><code>Initializing Terraform Cloud...\nDo you wish to proceed?\n  As part of migrating to Terraform Cloud, Terraform can optionally copy your\n  current workspace state to the configured Terraform Cloud workspace.\n\n  Answer \"yes\" to copy the latest state snapshot to the configured\n  Terraform Cloud workspace.\n\n  Answer \"no\" to ignore the existing state and just activate the configured\n  Terraform Cloud workspace with its existing state, if any.\n\n  Should Terraform migrate your existing state?\n\n  Enter a value: yes\n</code></pre> <p>You should then be informed the migration was successful:</p> <pre><code>Initializing provider plugins...\n- Reusing previous version of hashicorp/null from the dependency lock file\n- Using previously-installed hashicorp/null v3.2.1\n\nTerraform Cloud has been successfully initialized!\n\nYou may now begin working with Terraform Cloud. Try running \"terraform plan\" to\nsee any changes that are required for your infrastructure.\n\nIf you ever set or change modules or Terraform Settings, run \"terraform init\"\nagain to reinitialize your working directory.\n</code></pre> </li> </ol>"},{"location":"tfe_api/","title":"TFE API Compatiblity","text":"<p>OTF implements much of the Terraform Enterprise API. That means it also supports the use of the TFE terraform provider to manage resources on OTF.</p> <p>As such you can rely on the Hashicorp documentation for using the API and the provider with OTF. However, OTF doesn't implement all of the API endpoints, and for those endpoints it does support there can be differences in the request and response payloads. This document serves to record those differences where they exist.</p>"},{"location":"tfe_api/#oauth-clients-docs","title":"OAuth Clients [Docs]","text":"<p>(The OAuth Clients API essentially is an API for what are called VCS providers in both TFE and OTF).</p> <p>The create endpoint requires two parameters: <code>http-url</code> and <code>api-url</code>. OTF does too. However it only uses the <code>http-url</code> parameter for a VCS provider. This URL is the homepage or base URL of your VCS provider. OTF doesn't use the <code>api-url</code> parameter (which is documented as the base URL of the API of the provider) and instead it automatically infers it from the <code>http-url</code> parameter. .e.g for the public Github provider the <code>http-url</code> would be <code>https://github.com</code> and from this OTF automatically sets the API URL to be <code>https://api.github.com</code>.</p> <p>The create endpoint also takes a <code>service-provider</code> parameter. This can be set to any number of values such as <code>gitlab_community_edition</code> or <code>gitlab_enterprise_edition</code>. From this value OTF works out which \"kind\" of VCS provider to create (just as TFE does). However OTF makes no distinction between \"sub-kinds\": e.g. <code>gitlab_community_edition</code> or <code>gitlab_enterprise_edition</code> are both deemed by OTF to be the <code>github</code> kind and makes no further distinction.</p> <p>Note</p> <p>Github App installations are treatly differently in OTF and TFE. In TFE they're handled separately from \"VCS providers\": you create an installation at the admin level and then you're free to use that installation across organizations (I mgight be wrong on the exact details here...). Whereas in OTF they're treated as a VCS provider. That means you should be able to create a VCS provider for a Github App installation via the OAuth Clients create endpoint but that isn't yet currently implemented. (Raise an issue if you would like this).</p>"},{"location":"auth/org_token/","title":"Organization Tokens","text":"<p>Each organization can have an API token. Only an owner can create or delete the token.</p> <p>They are equivalent to organization tokens in Terraform Cloud. They possess the same permissions as those documented for Terraform Cloud.</p> <p>To manage your tokens, go to your organization main menu and select organization token:</p> <p></p> <p>Create the token:</p> <p></p> <p>The token is displayed:</p> <p></p> <p>Click the clipboard icon to copy the token to your system clipboard. You can then use the token to authenticate via the API or the <code>otf</code> CLI.</p>"},{"location":"auth/site_admins/","title":"Site Admins","text":"<p>Site admins possesses supreme privileges to an OTF installation. There are two ways to assume the role:</p> <ul> <li>Promote users to the role using the <code>--site-admins</code> flag.</li> <li>Set a token with the <code>--site-token</code> flag and use it to login as the built-in <code>site-admin</code> user</li> </ul>"},{"location":"auth/site_admins/#promoting-users","title":"Promoting users","text":"<p>To promote users to the role, simply set the <code>--site-admins</code> flag. There is no need to re-login.</p>"},{"location":"auth/site_admins/#site-token","title":"Site token","text":"<p>Set a site token with the <code>--site-token</code> flag. You can use the token with the API, CLI, and the web UI.</p> <p>To use it to login to the web UI, use the link in the bottom right corner of the login page:</p> <p> </p> <p>Note</p> <p>Keep the token secure. Anyone with access to the token has complete access to OTF. Use of the site admin token is recommended only for one-off administrative and testing purposes. You should use an Identity Provider in most cases.</p>"},{"location":"auth/user_token/","title":"User Tokens","text":"<p>A user can generate API tokens. The token shares the same permissions as the user.</p> <p>To manage your tokens, go to Profile &gt; Tokens.</p> <p> </p> <p>API tokens are not only used for programmatic access but for authenticating <code>terraform</code> and <code>otf</code>. For example, you can use <code>terraform login</code> to store a token on your workstation:</p> <pre><code>terraform login &lt;otf hostname&gt;\n</code></pre> <p>And follow the instructions. The token is persisted to a local credentials file for use by both <code>terraform</code> and <code>otf</code>.</p>"},{"location":"auth/providers/github/","title":"Github","text":"<p>Configure OTF to sign users in using their Github account.</p> <p>Create an OAuth application in Github by following their step-by-step instructions.</p> <ul> <li>Set application name to something appropriate, e.g. <code>otf</code></li> <li>Set the homepage URL to the URL of your otfd installation (although this is purely informational).</li> <li>Set an optional description.</li> <li> <p>Set the authorization callback URL to:</p> <p><code>https://&lt;otf_hostname&gt;/oauth/github/callback</code></p> </li> </ul> <p>Note</p> <p>It is recommended that you first set the <code>--hostname</code> flag to a hostname that is accessible by Github, and that you use this hostname in the authorization callback URL above.</p> <p>Once you've registered the application, note the client ID and secret.</p> <p>Set the following flags when running <code>otfd</code>:</p> <pre><code>otfd --github-client-id=&lt;client_id&gt; --github-client-secret=&lt;client_secret&gt;\n</code></pre> <p>If you're using Github Enterprise you'll also need to inform <code>otfd</code> of its hostname:</p> <pre><code>otfd --github-hostname=&lt;hostname&gt;\n</code></pre> <p>Now when you start <code>otfd</code>, navigate to its URL in your browser and you'll be prompted to login with Github.</p> <p></p> <p>Note</p> <p>In previous versions of OTF, Github organizations and teams were synchronised to OTF. This functionality was removed as it was deemed a security risk.</p>"},{"location":"auth/providers/gitlab/","title":"Gitlab","text":"<p>Configure OTF to sign users in using their Gitlab account.</p> <p>Create an OAuth application for your Gitlab group by following their step-by-step instructions.</p> <ul> <li>Set name to something appropriate, e.g. <code>otf</code></li> <li>Select <code>Confidential</code>.</li> <li>Select the <code>read_api</code> and <code>read_user</code> scopes.</li> <li> <p>Set the redirect URI to:</p> <p><code>https://&lt;otfd_install_hostname&gt;/oauth/gitlab/callback</code></p> </li> </ul> <p>Note</p> <p>It is recommended that you first set the <code>--hostname</code> flag to a hostname that is accessible by Gitlab, and that you use this hostname in the redirect URI above.</p> <p>Once you've created the application, note the Application ID and Secret.</p> <p>Set the following flags when running <code>otfd</code>:</p> <pre><code>otfd --gitlab-client-id=&lt;application_id&gt; --gitlab-client-secret=&lt;secret&gt;\n</code></pre> <p>If you're hosting your own Gitlab you'll also need to inform <code>otfd</code> of its hostname:</p> <pre><code>otfd --gitlab-hostname=&lt;hostname&gt;\n</code></pre> <p>Now when you start <code>otfd</code> navigate to its URL in your browser and you'll be prompted to login with Gitlab.</p> <p>Note</p> <p>In previous versions of OTF, Gitlab groups were synchronised to OTF. This functionality was removed as it was deemed a security risk.</p>"},{"location":"auth/providers/iap/","title":"Google IAP","text":"<p>OTF supports deployment using Google's Identity-Aware Proxy. Deploy an OTF cluster to Google Cloud (GCP) and enable IAP to authenticate users accessing the cluster. Only authenticated requests reach the cluster and each request contains information about the user. OTF verifies the requests and checks the user exists. If the user does not exist an account is created.</p> <p> IAP deployment with GCP Compute Engine / GKE (image sourced from Google Cloud documentation)</p>"},{"location":"auth/providers/iap/#verification","title":"Verification","text":"<p>OTF checks each incoming request for the presence of a signed IAP header. If present then it verifies the header's signed token to verify it originated from Google IAP and that it has not expired.</p> <p>You can also configure OTF to validate the audience token claim. Validating the audience checks OTF is indeed the intended recipient of the request. Follow Google's instructions for retrieving the audience string. Then set the --iap-google-jwt-audience <code>otfd</code> flag accordingly, e.g.:</p> <pre><code>otfd --google-jwt-audience /projects/project_number/apps/my_project_id\n</code></pre> <p>It is recommended you set this flag, especially for a production deployment.</p>"},{"location":"auth/providers/iap/#authentication","title":"Authentication","text":"<p>Authentication is delegated to IAP. From the Google Cloud documentation:</p> <p>...IAP checks the user's browser credentials. If none exist, the user is redirected to an OAuth 2.0 Google Account sign-in flow that stores a token in a browser cookie for future sign-ins... ...If the request credentials are valid, the authentication server uses those credentials to get the user's identity (email address and user ID). The authentication server then uses the identity to check the user's IAM role and check if the user is authorized to access the resource.</p>"},{"location":"auth/providers/iap/#authorization","title":"Authorization","text":"<p>IAP permits restricting which users can access the cluster (ibid):</p> <p>After authentication, IAP applies the relevant IAM policy to check if the user is authorized to access the requested resource. If the user has the IAP-secured Web App User role on the Google Cloud console project where the resource exists, they're authorized to access the application</p> <p>Whereas OTF remains responsible for determining what users can access, i.e. you assign users to teams and set team permissions to allow access to organizations and workspaces, etc.</p>"},{"location":"auth/providers/oidc/","title":"OIDC","text":"<p>You can configure OTF to sign users in using OpenID-Connect (OIDC). The OIDC authentication provider allows using an upstream identity provider (IdP) such as Azure AD, Google, or Dex.</p> <p>Configure OIDC on your preferred IdP (the extra process depends on the IdP):</p> <ul> <li>Set the OIDC scopes to match those configured in OTF (see below).</li> <li> <p>Set the redirect URI to:</p> <p><code>https://&lt;otfd_install_hostname&gt;/oauth/&lt;oidc_name&gt;/callback</code> (see below for configuring the <code>oidc_name</code>)</p> </li> </ul> <p>Once you've configured OIDC on the IdP, take a note of the client ID and client secret.</p> <p>Set the following flags when running <code>otfd</code>:</p> <ul> <li><code>--oidc-name=&lt;oidc_name&gt;</code> - the user-friendly name of the IdP. This can be something like <code>azure-sso</code>, or <code>google</code>. Note that this affects the redirect URI you configure on the IdP (see above).</li> <li><code>--oidc-issuer-url=&lt;issuer-url&gt;</code> - the URL of the IdP's OIDC configuration. This varies depending on the IdP.</li> <li><code>--oidc-client-id=&lt;client-id&gt;</code> - the client ID generated by the IdP.</li> <li><code>--oidc-client-secret=&lt;client-secret&gt;</code> - the client secret generated by the IdP.</li> </ul> <p>Optionally, you can set additional flags to override defaults:</p> <ul> <li><code>--oidc-scopes=&lt;scope1,scope2,...&gt;</code> - overrides the scopes. The default is <code>openid,profile</code>. You should at a minimum specify the <code>openid</code> scope.</li> <li><code>--oidc-username-claim=&lt;claim&gt;</code> - this determines which claim is mapped to a username in OTF. It defaults to <code>name</code>. You can set it to <code>name</code>, <code>email</code>, or <code>sub</code>.</li> </ul> <p>Note</p> <p>The choice of <code>--oidc-username-claim</code> has important security implications.  If users can log into the OIDC provider and modify their own <code>name</code> (full name) or <code>email</code>, those claims should not be used for OIDC authentication.  When combined with the <code>--site-admins</code> argument, users could gain administrative access simply by changing their full name or email to match yours. The OIDC specification strongly recommends the use of <code>sub</code> for uniquely identifying users. If you override the claim you may well need to override the scopes too, e.g. the <code>email</code> claim often needs the <code>email</code> scope configured.</p> <p>Now when you start <code>otfd</code>, navigate to its URL in your browser and you'll be prompted to login with your OIDC provider:</p> <p></p>"},{"location":"config/envvars/","title":"Environment variables","text":"<p>OTF can be configured from environment variables. Arguments can be converted to the equivalent env var by prefixing it with <code>OTF_</code>, replacing all <code>-</code> with <code>_</code>, and upper-casing it. For example:</p> <ul> <li><code>--secret</code> becomes <code>OTF_SECRET</code></li> <li><code>--site-token</code> becomes <code>OTF_SITE_TOKEN</code></li> </ul> <p>Env variables can be suffixed with <code>_FILE</code> to tell OTF to read the values from a file. This is useful for container environments where secrets are often mounted as files.</p>"},{"location":"config/flags/","title":"Flags","text":""},{"location":"config/flags/#-address","title":"<code>--address</code>","text":"<ul> <li>System: <code>otfd</code>, <code>otf-agent</code></li> <li>Default: <code>localhost:8080</code></li> </ul> <p>Sets the listening address of an <code>otfd</code> node.</p> <p>Set the port to an empty string or to <code>0</code> to choose a random available port.</p> <p>Set the address to an empty string to listen on all interfaces. For example, the following listens on all interfaces using a random port:</p> <pre><code>otfd --address :0\n</code></pre>"},{"location":"config/flags/#-applying-timeout","title":"<code>--applying-timeout</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: <code>24h</code></li> </ul> <p>Sets the amount of time a run is permitted to be in the <code>applying</code> state before it is canceled.</p>"},{"location":"config/flags/#-cache-expiry","title":"<code>--cache-expiry</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: <code>10 minutes</code></li> </ul> <p>Set the TTL for cache entries.</p>"},{"location":"config/flags/#-cache-size","title":"<code>--cache-size</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: <code>0</code> (unlimited)</li> </ul> <p>Cache size in MB. The cache is stored in RAM. Default is <code>0</code> which means it'll use an unlimited amount of RAM.</p> <p>It is recommended that you set this to an appropriate size in a production deployment, taking into consideration the cache expiry.</p>"},{"location":"config/flags/#-concurrency","title":"<code>--concurrency</code>","text":"<ul> <li>System: <code>otfd</code>, <code>otf-agent</code></li> <li>Default: 5</li> </ul> <p>Sets the number of workers that can process runs concurrently. Only applies to the fork executor.</p>"},{"location":"config/flags/#-default-engine","title":"<code>--default-engine</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: <code>terraform</code></li> </ul> <p>Specifies the default engine for new workspaces. Specify either <code>terraform</code> or <code>tofu</code>.</p>"},{"location":"config/flags/#-delete-configs-after","title":"<code>--delete-configs-after</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: <code>0</code></li> </ul> <p>Deletes configs older than the specified age. Specifying <code>0</code> disables config deletion.</p> <p>A config is the tarball of terraform configuration usually created for each run (retrying a run re-uses the existing run's config). Over a long period of time it can consume a lot of database disk space and the only other way to delete configs is to delete the parent workspace.</p> <p>Deleting a config also deletes any runs that use that config.</p> <p>Note that the only valid time units are <code>s</code>, <code>m</code>, and <code>h</code>. To specify longer periods of time you need to perform the necessary arithmetric, e.g. for 180 days, 180 x 24, which is <code>4320h</code>.</p>"},{"location":"config/flags/#-delete-runs-after","title":"<code>--delete-runs-after</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: <code>0</code></li> </ul> <p>Deletes runs older than the specified age. Specifying <code>0</code> disables run deletion.</p> <p>Deleting a run does not delete its associated config. To delete both the run and the config use <code>--delete-configs-after</code> instead.</p> <p>Note that the only valid time units are <code>s</code>, <code>m</code>, and <code>h</code>. To specify longer periods of time you need to perform the necessary arithmetric, e.g. for 180 days, 180 x 24, which is <code>4320h</code>.</p>"},{"location":"config/flags/#-engine-bins-dir","title":"<code>--engine-bins-dir</code>","text":"<ul> <li>System: <code>otfd</code>, <code>otf-agent</code></li> <li>Default: <code>/tmp/otf-engine-bins</code></li> </ul> <p>Sets the directory in which engine binaries are downloaded.</p>"},{"location":"config/flags/#-executor","title":"<code>--executor</code>","text":"<ul> <li>System: <code>otfd</code>, <code>otf-agent</code></li> <li>Default: <code>fork</code></li> </ul> <p>Specifies how runs should be executed.</p> <p>By default it is set to <code>fork</code>, which means executables such as <code>terraform</code> are forked as child processes of <code>otfd</code> (or <code>otf-agent</code> if the workspace is set to use an agent).</p> <p>If set to <code>kubernetes</code> then for each plan and apply a Kubernetes job is created. Executables such as <code>terraform</code> are then forked as child processes in the job pod.</p>"},{"location":"config/flags/#-github-client-id","title":"<code>--github-client-id</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: \"\"</li> </ul> <p>Github OAuth Client ID. Set this flag along with --github-client-secret to enable Github authentication.</p>"},{"location":"config/flags/#-github-client-secret","title":"<code>--github-client-secret</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: \"\"</li> </ul> <p>Github OAuth client secret. Set this flag along with --github-client-id to enable Github authentication.</p>"},{"location":"config/flags/#-gitlab-client-id","title":"<code>--gitlab-client-id</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: \"\"</li> </ul> <p>Gitlab OAuth Client ID. Set this flag along with --gitlab-client-secret to enable Gitlab authentication.</p>"},{"location":"config/flags/#-gitlab-client-secret","title":"<code>--gitlab-client-secret</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: \"\"</li> </ul> <p>Gitlab OAuth client secret. Set this flag along with --gitlab-client-id to enable Gitlab authentication.</p>"},{"location":"config/flags/#-google-jwt-audience","title":"<code>--google-jwt-audience</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: \"\"</li> </ul> <p>The Google JWT audience claim for validation. If unspecified then the audience claim is not validated. See the Google IAP document for more details.</p>"},{"location":"config/flags/#-hostname","title":"<code>--hostname</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: the value of <code>--address</code></li> </ul> <p>Sets the hostname advertised to external clients, for example:</p> <ul> <li>The hostname within the link beside the status check on a GitHub pull request.</li> <li>The hostname to which to send webhook events to trigger runs when a workspace is connected to a GitHub repository (see <code>--webhook-hostname</code> below.</li> </ul> <p>It is advisable to set this flag in a production deployment. Otherwise it defaults to the listening address set with <code>--address</code> which is unlikely to be accessible to external clients.</p>"},{"location":"config/flags/#-kubernetes-request-cpu","title":"<code>--kubernetes-request-cpu</code>","text":"<ul> <li>System: <code>otfd</code>, <code>otf-agent</code></li> <li>Default: <code>500m</code></li> </ul> <p>Set the requested CPU resources for a kubernetes job.</p>"},{"location":"config/flags/#-kubernetes-request-memory","title":"<code>--kubernetes-request-memory</code>","text":"<ul> <li>System: <code>otfd</code>, <code>otf-agent</code></li> <li>Default: <code>128Mi</code></li> </ul> <p>Set the requested memory resources for a kubernetes job.</p>"},{"location":"config/flags/#-kubernetes-ttl-after-finish","title":"<code>--kubernetes-ttl-after-finish</code>","text":"<ul> <li>System: <code>otfd</code>, <code>otf-agent</code></li> <li>Default: <code>1h</code></li> </ul> <p>Set the TTL for how long before a kubernetes job is deleted after it has finished.</p>"},{"location":"config/flags/#-log-format","title":"<code>--log-format</code>","text":"<ul> <li>System: <code>otfd</code>, <code>otf-agent</code></li> <li>Default: <code>default</code></li> </ul> <p>Set the logging format. Can be one of:</p> <ul> <li><code>default</code>: human-friendly, not easy to parse, writes to stderr</li> <li><code>text</code>: sequence of key=value pairs, writes to stdout</li> <li><code>json</code>: json format, writes to stdout</li> </ul>"},{"location":"config/flags/#-max-config-size","title":"<code>--max-config-size</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: <code>104865760</code> (10MiB)</li> </ul> <p>Maximum permitted configuration upload size. This refers to the size of the (compressed) configuration tarball that <code>terraform</code> uploads to OTF at the start of a remote plan/apply.</p>"},{"location":"config/flags/#-oidc-client-id","title":"<code>--oidc-client-id</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: \"\"</li> </ul> <p>OIDC Client ID. Set this flag along with --oidc-client-secret to enable OIDC authentication.</p>"},{"location":"config/flags/#-oidc-client-secret","title":"<code>--oidc-client-secret</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: \"\"</li> </ul> <p>OIDC Client Secret. Set this flag along with --oidc-client-id to enable OIDC authentication.</p>"},{"location":"config/flags/#-oidc-issuer-url","title":"<code>--oidc-issuer-url</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: \"\"</li> </ul> <p>OIDC Issuer URL for OIDC authentication.</p>"},{"location":"config/flags/#-oidc-name","title":"<code>--oidc-name</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: \"\"</li> </ul> <p>User friendly OIDC name - this is the name of the OIDC provider shown on the login prompt on the web UI.</p>"},{"location":"config/flags/#-oidc-scopes","title":"<code>--oidc-scopes</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: [openid,profile]</li> </ul> <p>OIDC scopes to request from OIDC provider.</p>"},{"location":"config/flags/#-oidc-username-claim","title":"<code>--oidc-username-claim</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: \"name\"</li> </ul> <p>OIDC claim for mapping to an OTF username. Must be one of <code>name</code>, <code>email</code>, or <code>sub</code>.</p>"},{"location":"config/flags/#-planning-timeout","title":"<code>--planning-timeout</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: <code>2h</code></li> </ul> <p>Sets the amount of time a run is permitted to be in the <code>planning</code> state before it is canceled.</p>"},{"location":"config/flags/#-plugin-cache","title":"<code>--plugin-cache</code>","text":"<ul> <li>System: <code>otfd</code>, <code>otf-agent</code></li> <li>Default: <code>false</code></li> </ul> <p>Enable the shared provider plugin cache. Note that it is only concurrency safe in OpenTofu v1.10.0 and greater.</p>"},{"location":"config/flags/#-plugin-cache-dir","title":"<code>--plugin-cache-dir</code>","text":"<ul> <li>System: <code>otfd</code>, <code>otf-agent</code></li> <li>Default: <code>&lt;random directory in system temp directory&gt;</code></li> </ul> <p>Directory for the shared provider plugin cache.</p>"},{"location":"config/flags/#-restrict-org-creation","title":"<code>--restrict-org-creation</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: false</li> </ul> <p>Restricts the ability to create organizations to users possessing the site admin role. By default any user can create organizations.</p>"},{"location":"config/flags/#-secret","title":"<code>--secret</code>","text":"<ul> <li>Required</li> <li>System: <code>otfd</code></li> <li>Default: \"\"</li> </ul> <p>Hex-encoded 16-byte secret for performing cryptographic work. You should use a cryptographically secure random number generator, e.g. <code>openssl</code>:</p> <pre><code>&gt; openssl rand -hex 16\n6b07b57377755b07cf61709780ee7484\n</code></pre> <p>Note</p> <p>The secret is required. It must be exactly 16 bytes in size, and it must be hex-encoded.</p>"},{"location":"config/flags/#-site-admins","title":"<code>--site-admins</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: []</li> </ul> <p>Promote users to the role of site admin. Specify their usernames, separated by a comma. For example:</p> <pre><code>otfd --site-admins bob@example.com,alice@example.com\n</code></pre> <p>Users are automatically created if they don't exist already.</p>"},{"location":"config/flags/#-site-token","title":"<code>--site-token</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: \"\"</li> </ul> <p>The site token for authenticating with the built-in <code>site-admin</code> user, e.g.:</p> <pre><code>otfd --site-token=643f57a1016cdde7e7e39914785d36d61fd\n</code></pre> <p>The default, an empty string, disables the site admin account.</p>"},{"location":"config/flags/#-url","title":"<code>--url</code>","text":"<ul> <li>System: <code>otf-agent</code>, <code>otf</code></li> <li>Default: <code>https://localhost:8080</code></li> </ul> <p>Specifies the URL of <code>otfd</code> to connect to. You must include the scheme, which is either <code>https://</code> or <code>http://</code>.</p>"},{"location":"config/flags/#-v-v","title":"<code>--v</code>, <code>-v</code>","text":"<ul> <li>System: <code>otfd</code>, <code>otf-agent</code></li> <li>Default: <code>0</code></li> </ul> <p>Set logging verbosity. The higher the number the more verbose the logs. Each number translates to a <code>level</code> log field like so:</p> verbosity level 0 INFO 1 DEBUG 2 DEBUG-1 3 DEBUG-2 n DEBUG-(n+1)"},{"location":"config/flags/#-webhook-hostname","title":"<code>--webhook-hostname</code>","text":"<ul> <li>System: <code>otfd</code></li> <li>Default: the value of <code>--hostname</code></li> </ul> <p>Overrides <code>--hostname</code> specifically for webhooks. This is useful if you want to set a separate firewalled inbound route for VCS providers (such as GitHub) via which to send their webhook events.</p>"},{"location":"vcs_providers/","title":"VCS Providers","text":"<p>To connect workspaces and modules to git repositories containing Terraform configurations, you need to provide OTF with access to your VCS provider. You have a choice of four providers:</p> <ul> <li>Github app</li> <li>Github personal access token</li> <li>Gitlab personal access token</li> <li>Forgejo/Gitea personal access token</li> </ul>"},{"location":"vcs_providers/#walkthrough","title":"Walkthrough","text":"<p>This walkthrough shows you how to create a VCS provider via the web UI.</p> <p>On your organization's main menu, select VCS providers.</p> <p></p> <p>You are presented with a choice of providers to create:</p> <p></p> <p>In this walkthrough we will create a provider using a Github personal access token.</p> <p>Select New Github VCS Provider (Personal Token). You are then presented with a form on which to enter the token:</p> <p></p> <p>Click the personal token link. It'll take you to Github where you can create the token. Create a classic token with the repo scope (or you can create a fine-tuned token with the equivalent permissions). The token permits OTF to access your git repository and retrieve terraform configuration. Once you've generated the token, copy and paste it into the Token field. Optionally you can also assign the provider a name.</p> <p>Create the provider and it'll appear on the list of providers:</p> <p></p> <p>You can now proceed to connecting workspaces (see below) and publishing modules.</p>"},{"location":"vcs_providers/#connecting-a-workspace","title":"Connecting a workspace","text":"<p>Once you have a provider you can connect a workspace to a git repository for that provider.</p> <p>Select a workspace. Go to settings.</p> <p></p> <p>Click Connect to VCS.</p> <p></p> <p>Select the provider.</p> <p></p> <p>You'll then be presented with a list of repositories. Select the repository containing the terraform configuration you want to use in your workspace. If you cannot see your repository you can enter its name.</p> <p></p> <p>Once connected you can start a run via the web UI. On the workspace page select the start run drop-down box and select an option to either start a plan or both a plan and an apply.</p> <p></p> <p>That will start a run, retrieving the configuration from the repository, and you will see the progress of its plan and apply.</p> <p></p>"},{"location":"vcs_providers/forgejo/","title":"Forgejo","text":"<p>OTF can use Forgejo/Gitea for both authentication (OIDC) and as a VCS provider.  Here's a setup guide.</p>"},{"location":"vcs_providers/forgejo/#compatibility","title":"Compatibility","text":"<p>At time of writing (May 2025), the APIs of Gitea and Forgejo are largely compatible, allowing OTF to work with both.  There are only some small differences in naming; OTF uses the webhook type \"gitea\", which is supported by both.</p> <p>This guide is tested to work with Forgejo 11.0.1, and Gitea 1.24.0.</p>"},{"location":"vcs_providers/forgejo/#authentication","title":"Authentication","text":"<p>OTF's general OIDC instructions apply.  This document only provides some forgejo-specific details.</p>"},{"location":"vcs_providers/forgejo/#setting-up-forgejogitea","title":"Setting up Forgejo/Gitea","text":"<p>Some examples exist in the forgejo documentation.</p> <p>Forgejo is set up by going to the \"Applications\" tab of:</p> <ol> <li>User settings \u2192 Applications \u2192 Manage OAuth2 applications</li> <li>An organization page \u2192 Settings \u2192 Applications</li> <li>Site administration \u2192 Integrations \u2192 Applications</li> </ol> <p>The differences between these options are who configures/manages it, and who can log in through it.</p> <p>Set it up with the following fields:</p> <ul> <li>The Application Name can be anything.</li> <li>The Redirect URI should be set as described in the OTF OIDC instructions.</li> <li>The \"Confidential client\" box should be checked.</li> </ul> <p>It will generate a client ID and client secret, to be given to OTF (below).</p>"},{"location":"vcs_providers/forgejo/#setting-up-otf","title":"Setting up OTF","text":"<p>The following OTF parameters make sense:</p> <ul> <li><code>--oidc-name</code> can be anything.  It is never used.</li> <li><code>--oidc-issuer-url</code> is the URL of the forgejo server, with a trailing slash.  Example: <code>https://forgejo.example.com/</code>.</li> <li><code>--oidc-scopes</code> should be <code>openid,profile</code>.</li> <li><code>--oidc-client-id</code> is the client ID value provided by forgejo.</li> <li><code>--oidc-client-secret</code> is the client secret value provided by forgejo.</li> <li><code>--oidc-username-claim=sub</code> tells it to use the <code>sub</code> field for usernames.</li> </ul> <p>Note</p> <p><code>--oidc-username-claim=sub</code> is the only secure setting for the Forgejo OIDC Provider, because users are able to modify their own fullname and email fields.  Recent versions of Gitea have a bit more control over that, see the <code>USER_DISABLED_FEATURES</code> setting in the admin section. Unfortunately, in Gitea/Forgejo, the <code>sub</code> field returns a numeric ID, not a username, which means <code>--site-admins</code> must also be specified numerically.</p> <p>If all goes well, OTF's web UI should redirect you to log in using forgejo.</p>"},{"location":"vcs_providers/forgejo/#vcs","title":"VCS","text":""},{"location":"vcs_providers/forgejo/#requirements","title":"Requirements","text":"<p>If connecting to the forgejo server with \"https\", it is assumed that its certificate was signed by a CA which is trusted by OTF.</p> <p>You will need a personal access token for a user on that Forgejo instance.  It can be either your own user, or a dedicated service account.</p> <p>The user needs repository administration privileges, as these are necessary to install webhooks.</p> <p>The personal access token needs the following permissions:</p> <ul> <li>repository read and write</li> <li>user read</li> </ul>"},{"location":"vcs_providers/forgejo/#setup","title":"Setup","text":"<p>In OTF, VCS providers are set up within an organization.  Select (or create) an organization, go to the VCS Providers tab, and click New Forgejo VCS Provider (Personal Token).  Give it a name, paste in the token, and ensure the URL is correct (e.g. <code>https://forgejo.example.com</code>).</p> <p>Once the VCS provider is created, you can attach it to a workspace.  Go to the workspace's Settings menu, click \"Connect to VCS\", select the VCS provider, and select a git repo or type it in.  This will install a webhook, setting up OTF to receive updates for pushes and pull requests.</p> <p>To verify that it all works, you can go to the repo's settings page, to the Webhooks tab, select the webhook it installed, and click \"Test delivery\" at the bottom of the page.  If all goes well, OTF will receive the webhook, create a Run, check out the default branch, run <code>terraform plan</code> on it.  When you click on the Run, it will show you the log.</p>"}]}